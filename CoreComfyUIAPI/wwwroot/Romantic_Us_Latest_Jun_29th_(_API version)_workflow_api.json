{
  "prompt": 
    {
      "4": {
        "inputs": {
          "ckpt_name": "turbovisionxlSuperFastXLBasedOnNew_tvxlV431Bakedvae.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
          "title": "Load Checkpoint"
        }
      },
      "6": {
        "inputs": {
          "text": "a male couple at the Prom",
          "clip": [
            "4",
            1
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "7": {
        "inputs": {
          "text": "text, watermark, (NSFW:1.6), naked, nudity, (breasts:1.8), nipples:1.8",
          "clip": [
            "4",
            1
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Negative Prompt)"
        }
      },
      "10": {
        "inputs": {
          "preset": "PLUS (high strength)",
          "model": [
            "4",
            0
          ]
        },
        "class_type": "IPAdapterUnifiedLoader",
        "_meta": {
          "title": "IPAdapter Unified Loader"
        }
      },
      "12": {
        "inputs": {
          "weight_style": 0.85,
          "weight_composition": 0.81,
          "expand_style": false,
          "combine_embeds": "average",
          "start_at": 0,
          "end_at": 1,
          "embeds_scaling": "V only",
          "model": [
            "10",
            0
          ],
          "ipadapter": [
            "10",
            1
          ],
          "image_style": [
            "86",
            0
          ],
          "image_composition": [
            "86",
            0
          ],
          "clip_vision": [
            "20",
            0
          ]
        },
        "class_type": "IPAdapterStyleComposition",
        "_meta": {
          "title": "IPAdapter Style & Composition SDXL"
        }
      },
      "14": {
        "inputs": {
          "image": "2024-06-16_17-21-05_8302.png",
          "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Load Image Base Style"
        }
      },
      "15": {
        "inputs": {
          "image": "image (1) (1).png",
          "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Load Image Face A"
        }
      },
      "20": {
        "inputs": {
          "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
        },
        "class_type": "CLIPVisionLoader",
        "_meta": {
          "title": "Load CLIP Vision"
        }
      },
      "26": {
        "inputs": {
          "strength": 0.7000000000000001,
          "start_percent": 0,
          "end_percent": 0.999,
          "positive": [
            "6",
            0
          ],
          "negative": [
            "7",
            0
          ],
          "control_net": [
            "27",
            0
          ],
          "image": [
            "14",
            0
          ]
        },
        "class_type": "ControlNetApplyAdvanced",
        "_meta": {
          "title": "Apply ControlNet (Advanced)"
        }
      },
      "27": {
        "inputs": {
          "control_net_name": "control-lora-canny-rank256.safetensors"
        },
        "class_type": "ControlNetLoader",
        "_meta": {
          "title": "Load ControlNet Model"
        }
      },
      "29": {
        "inputs": {
          "width": 864,
          "height": 1080,
          "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
          "title": "Empty Latent Image"
        }
      },
      "30": {
        "inputs": {
          "samples": [
            "125",
            0
          ],
          "vae": [
            "4",
            2
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "32": {
        "inputs": {
          "enabled": true,
          "swap_model": "inswapper_128.onnx",
          "facedetection": "YOLOv5n",
          "face_restore_model": "GFPGANv1.4.pth",
          "face_restore_visibility": 1,
          "codeformer_weight": 0.5,
          "detect_gender_input": "no",
          "detect_gender_source": "no",
          "input_faces_index": "0",
          "source_faces_index": "0",
          "console_log_level": 1,
          "input_image": [
            "30",
            0
          ],
          "source_image": [
            "15",
            0
          ]
        },
        "class_type": "ReActorFaceSwap",
        "_meta": {
          "title": "ReActor ðŸŒŒ Fast Face Swap A"
        }
      },
      "63": {
        "inputs": {
          "image": "Brad Pitt 2.jpg",
          "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "Load Image Face B"
        }
      },
      "68": {
        "inputs": {
          "enabled": true,
          "swap_model": "inswapper_128.onnx",
          "facedetection": "YOLOv5n",
          "face_restore_model": "GFPGANv1.4.pth",
          "face_restore_visibility": 1,
          "codeformer_weight": 0.5,
          "detect_gender_input": "no",
          "detect_gender_source": "no",
          "input_faces_index": "1",
          "source_faces_index": "0",
          "console_log_level": 1,
          "input_image": [
            "32",
            0
          ],
          "source_image": [
            "63",
            0
          ]
        },
        "class_type": "ReActorFaceSwap",
        "_meta": {
          "title": "ReActor ðŸŒŒ Fast Face Swap B"
        }
      },
      "86": {
        "inputs": {
          "height": 1080,
          "width": 864,
          "interpolation_mode": "bicubic",
          "image": [
            "14",
            0
          ]
        },
        "class_type": "JWImageResize",
        "_meta": {
          "title": "Image Resize"
        }
      },
      "87": {
        "inputs": {
          "multiplier": 0.4,
          "model": [
            "12",
            0
          ]
        },
        "class_type": "RescaleCFG",
        "_meta": {
          "title": "RescaleCFG"
        }
      },
      "110": {
        "inputs": {
          "images": [
            "32",
            0
          ]
        },
        "class_type": "PreviewImage",
        "_meta": {
          "title": "Preview Image Face A"
        }
      },
      "111": {
        "inputs": {
          "images": [
            "30",
            0
          ]
        },
        "class_type": "PreviewImage",
        "_meta": {
          "title": "Preview Image Generated"
        }
      },
      "125": {
        "inputs": {
          "seed": 625731254565407,
          "steps": 30,
          "cfg": 3,
          "sampler_name": "euler_ancestral",
          "scheduler": "ddim_uniform",
          "denoise": 0.98,
          "model": [
            "87",
            0
          ],
          "positive": [
            "26",
            0
          ],
          "negative": [
            "26",
            1
          ],
          "latent_image": [
            "29",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "128": {
        "inputs": {
          "bbox_model_name": "bbox/face_yolov8m.pt",
          "bbox_threshold": 0.5,
          "bbox_dilation": 10,
          "bbox_crop_factor": 3,
          "bbox_drop_size": 100,
          "sam_model_name": "sam_vit_b_01ec64.pth",
          "sam_dilation": 0,
          "sam_threshold": 0.93,
          "bbox_expansion": 0,
          "mask_hint_threshold": 0.7,
          "mask_hint_use_negative": "False",
          "morphology_operation": "dilate",
          "morphology_distance": 0,
          "blur_radius": 9,
          "sigma_factor": 1,
          "image": [
            "30",
            0
          ],
          "swapped_image": [
            "68",
            0
          ]
        },
        "class_type": "ReActorMaskHelper",
        "_meta": {
          "title": "ReActor ðŸŒŒ Masking Helper"
        }
      },
      "131": {
        "inputs": {
          "images": [
            "68",
            0
          ]
        },
        "class_type": "PreviewImage",
        "_meta": {
          "title": "Preview Image Face B"
        }
      },
      "132": {
        "inputs": {
          "filename_prefix": "Couples",
          "images": [
            "128",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "Save Image"
        }
      }
    }
  }